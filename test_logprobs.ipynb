{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3f9e11-abdd-48d4-bb21-5deda533d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from math import exp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4888ad5-1656-4566-b680-ccc3c7d16150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Question: Give me the name of the president of US at year 2000, return only the name, and nothing else<br>Answer: Bill Clinton<br><span style='color: cyan'>Output token 1:</span><br>Bill, <span style='color: darkorange'>logprobs:</span> -2.868329e-05, <span style='color: magenta'>linear probability:</span> 100.0%<br>William, <span style='color: darkorange'>logprobs:</span> -10.500029, <span style='color: magenta'>linear probability:</span> 0.0%<br> Bill, <span style='color: darkorange'>logprobs:</span> -14.500029, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 2:</span><br> Clinton, <span style='color: darkorange'>logprobs:</span> -1.9361265e-07, <span style='color: magenta'>linear probability:</span> 100.0%<br> Clint, <span style='color: darkorange'>logprobs:</span> -17.125, <span style='color: magenta'>linear probability:</span> 0.0%<br> Cl, <span style='color: darkorange'>logprobs:</span> -17.5, <span style='color: magenta'>linear probability:</span> 0.0%<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_completion(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    max_tokens=500,\n",
    "    temperature=0,\n",
    "    stop=None,\n",
    "    seed=123,\n",
    "    tools=None,\n",
    "    logprobs=None,  # whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message..\n",
    "    top_logprobs=None,\n",
    ") -> str:\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop\": stop,\n",
    "        \"seed\": seed,\n",
    "        \"logprobs\": logprobs,\n",
    "        \"top_logprobs\": top_logprobs,\n",
    "    }\n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "    return completion\n",
    "\n",
    "TEST_PROMPT = \"\"\"Give me the name of the president of US at year 2000, return only the name, and nothing else\"\"\"\n",
    "api_response = get_completion(\n",
    "    [{\"role\": \"user\", \"content\": TEST_PROMPT}],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3,\n",
    ")\n",
    "generate_answer = api_response.choices[0].message.content\n",
    "\n",
    "possible_tokens = api_response.choices[0].logprobs.content\n",
    "html_content = f\"Question: {TEST_PROMPT}<br>Answer: {generate_answer}<br>\"\n",
    "for i, token in enumerate(possible_tokens, start=1):\n",
    "    html_content += f\"<span style='color: cyan'>Output token {i}:</span><br>\"\n",
    "    for j, logprob in enumerate(token.top_logprobs):\n",
    "        html_content += (\n",
    "            f\"{logprob.token}, <span style='color: darkorange'>logprobs:</span> {logprob.logprob}, \"\n",
    "            f\"<span style='color: magenta'>linear probability:</span> {np.round(np.exp(logprob.logprob)*100,2)}%<br>\"\n",
    "        )\n",
    "display(HTML(html_content))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50fc5d-a1c3-426d-a58b-0b1d622232cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a8e3978-3bf9-4721-b8b6-4ceb2afe2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"You are provided with an article: {article}. Your task is to answer the user's question solely based on the information within this article. \\\n",
    "Before responding, assess whether the article contains enough information to answer the question accurately. \\\n",
    "Then, proceed to answer the question. If the article lacks sufficient information, respond with \"Do not have sufficent information to answer the question\". \\\n",
    "After providing your answer, evaluate whether your response is entirely based on the article's content and effectively answers the user's question.\"\"\"\n",
    "SYS_PROMPT_1 = \"\"\"You are provided with an article: {article}. Your task is to answer the user's question solely based on the information within this article. \\\n",
    "But before you answer the question, assess whether the article contains enough information to answer the question accurately, Yes or No only, nothing else.\"\"\"\n",
    "SYS_PROMPT_2 = \"\"\"You are provided with an article: {article}. Your task is to answer the user's question solely based on the information within this article. \\\n",
    "If you do not have sufficient information from the article to answer the question, respond with \"Do not have sufficent information to answer the question\".\"\"\"\n",
    "SYS_PROMPT_3 = \"\"\"You are given an article: {article}. You are also given an answer to user's question: {answer}.\\\n",
    "Evaluate whether the answer is entirely based on the article's content and effectively answers the user's question, Yes or No, nothing else.\"\"\"\n",
    "USER_PROMPT = \"\"\"Question: {question}\"\"\"\n",
    "#ARTICLE = \"The president of the US at year of 2000 is Bill Clinton, and the president of the US at year 2024 is Joe Biden\"\n",
    "#QUESTION = \"Give me the name of the president of US at year 2026, return only the name, and nothing else\"\n",
    "ARTICLE=\"\"\"Augusta Ada King, Countess of Lovelace (née Byron; 10 December 1815 – 27 November 1852) was an English mathematician and writer, chiefly known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation.\n",
    "Ada Byron was the only legitimate child of poet Lord Byron and reformer Lady Byron. All Lovelace's half-siblings, Lord Byron's other children, were born out of wedlock to other women. Byron separated from his wife a month after Ada was born and left England forever. He died in Greece when Ada was eight. Her mother was anxious about her upbringing and promoted Ada's interest in mathematics and logic in an effort to prevent her from developing her father's perceived insanity. Despite this, Ada remained interested in him, naming her two sons Byron and Gordon. Upon her death, she was buried next to him at her request. Although often ill in her childhood, Ada pursued her studies assiduously. She married William King in 1835. King was made Earl of Lovelace in 1838, Ada thereby becoming Countess of Lovelace.\n",
    "Her educational and social exploits brought her into contact with scientists such as Andrew Crosse, Charles Babbage, Sir David Brewster, Charles Wheatstone, Michael Faraday, and the author Charles Dickens, contacts which she used to further her education. Ada described her approach as \"poetical science\" and herself as an \"Analyst (& Metaphysician)\".\n",
    "When she was eighteen, her mathematical talents led her to a long working relationship and friendship with fellow British mathematician Charles Babbage, who is known as \"the father of computers\". She was in particular interested in Babbage's work on the Analytical Engine. Lovelace first met him in June 1833, through their mutual friend, and her private tutor, Mary Somerville.\n",
    "Between 1842 and 1843, Ada translated an article by the military engineer Luigi Menabrea (later Prime Minister of Italy) about the Analytical Engine, supplementing it with an elaborate set of seven notes, simply called \"Notes\".\n",
    "Lovelace's notes are important in the early history of computers, especially since the seventh one contained what many consider to be the first computer program—that is, an algorithm designed to be carried out by a machine. Other historians reject this perspective and point out that Babbage's personal notes from the years 1836/1837 contain the first programs for the engine. She also developed a vision of the capability of computers to go beyond mere calculating or number-crunching, while many others, including Babbage himself, focused only on those capabilities. Her mindset of \"poetical science\" led her to ask questions about the Analytical Engine (as shown in her notes) examining how individuals and society relate to technology as a collaborative tool.\n",
    "\"\"\"\n",
    "QUESTION=\"What concepts did Lovelace build with Charles Babbage\"\n",
    "TOP_LOGPROBS_NUM = 3\n",
    "#MODEL_NAME = \"gpt-4o-2024-08-06\"\n",
    "MODEL_NAME=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25ec8a09-32db-4ddc-af4f-18316297574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(BaseModel):\n",
    "    pre_validation: str = Field(\n",
    "        description=\"\"\"Before you answer, consider if you have sufficient information from the article to answer the question, respond with \"Yes\" or \"No\" only, nothing else.\"\"\"\n",
    "    )\n",
    "    question_answer: str = Field(\n",
    "        description=\"The answer of the question, nothing else. Anser Unknow if you do not have sufficient information from the article to answer the question.\"\n",
    "    )\n",
    "    post_validation: str = Field(\n",
    "        descrption=\"\"\"After providing your answer, evaluate whether your response is entirely based on the article's content and effectively answers the user's question., respond with \"Yes\" or \"No\" only, nothing else.\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "test_all_completion = client.beta.chat.completions.parse(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT.format(article=ARTICLE)},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT.format(question=QUESTION)},\n",
    "    ],\n",
    "    response_format=ResponseFormat,\n",
    "    logprobs=True,\n",
    "    top_logprobs=TOP_LOGPROBS_NUM,\n",
    ")\n",
    "\n",
    "test_all_message = test_all_completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8ea51e0-c748-49ab-b976-95aa08fcbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What concepts did Lovelace build with Charles Babbage\n",
      "Pre validation:\t\tYes\n",
      "Question anser:\t\tLovelace built concepts around the capabilities of computers to go beyond mere calculating or number-crunching, focusing on technology as a collaborative tool, and she developed the first computer program through her notes on the Analytical Engine.\n",
      "Post validation:\tYes\n",
      "Token 1 : '{\"'            : 100.0% \u001b[0m\t|\t'{'             : 0.0  % \u001b[0m\t|\t'{\\n'           : 0.0  % \u001b[0m\n",
      "Token 2 : 'pre'           : 100.0% \u001b[0m\t|\t'pr'            : 0.0  % \u001b[0m\t|\t'p'             : 0.0  % \u001b[0m\n",
      "Token 3 : '_validation'   : 100.0% \u001b[0m\t|\t'_valid'        : 0.0  % \u001b[0m\t|\t'_val'          : 0.0  % \u001b[0m\n",
      "Token 4 : '\":\"'           : 100.0% \u001b[0m\t|\t'\":\"\",\"'        : 0.0  % \u001b[0m\t|\t'\":\"\\''         : 0.0  % \u001b[0m\n",
      "Token 5 : \u001b[1m'Yes'           : 99.75% \u001b[0m\t|\t\u001b[1m'No'            : 0.25 % \u001b[0m\t|\t' Yes'          : 0.0  % \u001b[0m\n",
      "Token 6 : '\",\"'           : 100.0% \u001b[0m\t|\t'.\",\"'          : 0.0  % \u001b[0m\t|\t\"','\"           : 0.0  % \u001b[0m\n",
      "Token 7 : 'question'      : 100.0% \u001b[0m\t|\t'quest'         : 0.0  % \u001b[0m\t|\t'ques'          : 0.0  % \u001b[0m\n",
      "Token 8 : '_answer'       : 100.0% \u001b[0m\t|\t'_ans'          : 0.0  % \u001b[0m\t|\t'_an'           : 0.0  % \u001b[0m\n",
      "Token 9 : '\":\"'           : 100.0% \u001b[0m\t|\t'\":\"\\''         : 0.0  % \u001b[0m\t|\t'\":\"\",\"'        : 0.0  % \u001b[0m\n",
      "Token 10: 'L'             : 77.62% \u001b[0m\t|\t'Ada'           : 22.24% \u001b[0m\t|\t'She'           : 0.05 % \u001b[0m\n",
      "Token 11: 'ovel'          : 100.0% \u001b[0m\t|\t'oving'         : 0.0  % \u001b[0m\t|\t'overs'         : 0.0  % \u001b[0m\n",
      "Token 12: 'ace'           : 100.0% \u001b[0m\t|\t'aces'          : 0.0  % \u001b[0m\t|\t'aced'          : 0.0  % \u001b[0m\n",
      "Token 13: ' built'        : 90.98% \u001b[0m\t|\t' and'          : 5.13 % \u001b[0m\t|\t' worked'       : 2.75 % \u001b[0m\n",
      "Token 14: ' concepts'     : 70.19% \u001b[0m\t|\t' the'          : 7.4  % \u001b[0m\t|\t' on'           : 7.4  % \u001b[0m\n",
      "Token 15: ' related'      : 83.49% \u001b[0m\t|\t' around'       : 9.97 % \u001b[0m\t|\t' regarding'    : 4.16 % \u001b[0m\n",
      "Token 16: ' the'          : 99.84% \u001b[0m\t|\t' B'            : 0.13 % \u001b[0m\t|\t' her'          : 0.02 % \u001b[0m\n",
      "Token 17: ' Analytical'   : 98.28% \u001b[0m\t|\t' capabilities' : 1.24 % \u001b[0m\t|\t' potential'    : 0.19 % \u001b[0m\n",
      "Token 18: ' of'           : 99.98% \u001b[0m\t|\t' and'          : 0.02 % \u001b[0m\t|\t' beyond'       : 0.0  % \u001b[0m\n",
      "Token 19: ' the'          : 64.09% \u001b[0m\t|\t' computers'    : 34.31% \u001b[0m\t|\t' B'            : 1.51 % \u001b[0m\n",
      "Token 20: ' to'           : 63.47% \u001b[0m\t|\t' beyond'       : 26.46% \u001b[0m\t|\t','             : 6.69 % \u001b[0m\n",
      "Token 21: ' go'           : 99.82% \u001b[0m\t|\t' extend'       : 0.1  % \u001b[0m\t|\t' perform'      : 0.04 % \u001b[0m\n",
      "Token 22: ' beyond'       : 100.0% \u001b[0m\t|\t' Beyond'       : 0.0  % \u001b[0m\t|\t'Beyond'        : 0.0  % \u001b[0m\n",
      "Token 23: ' mere'         : 99.63% \u001b[0m\t|\t' pure'         : 0.25 % \u001b[0m\t|\t' merely'       : 0.08 % \u001b[0m\n",
      "Token 24: ' calculating'  : 72.91% \u001b[0m\t|\t' calculation'  : 26.82% \u001b[0m\t|\t' calculations' : 0.26 % \u001b[0m\n",
      "Token 25: ' or'           : 98.88% \u001b[0m\t|\t','             : 0.86 % \u001b[0m\t|\t' and'          : 0.25 % \u001b[0m\n",
      "Token 26: ' number'       : 100.0% \u001b[0m\t|\t' numerical'    : 0.0  % \u001b[0m\t|\t' numbers'      : 0.0  % \u001b[0m\n",
      "Token 27: '-cr'           : 99.99% \u001b[0m\t|\t' crunch'       : 0.01 % \u001b[0m\t|\t' cr'           : 0.0  % \u001b[0m\n",
      "Token 28: 'unch'          : 100.0% \u001b[0m\t|\t'ushing'        : 0.0  % \u001b[0m\t|\t'UNCH'          : 0.0  % \u001b[0m\n",
      "Token 29: 'ing'           : 100.0% \u001b[0m\t|\t'ings'          : 0.0  % \u001b[0m\t|\t'inging'        : 0.0  % \u001b[0m\n",
      "Token 30: ','             : 78.55% \u001b[0m\t|\t'.'             : 13.65% \u001b[0m\t|\t' and'          : 7.31 % \u001b[0m\n",
      "Token 31: ' and'          : 31.67% \u001b[0m\t|\t' examining'    : 24.67% \u001b[0m\t|\t' as'           : 14.96% \u001b[0m\n",
      "Token 32: ' on'           : 97.63% \u001b[0m\t|\t' instead'      : 2.3  % \u001b[0m\t|\t' also'         : 0.07 % \u001b[0m\n",
      "Token 33: ' how'          : 29.64% \u001b[0m\t|\t' technology'   : 26.15% \u001b[0m\t|\t' the'          : 23.08% \u001b[0m\n",
      "Token 34: ' as'           : 99.9 % \u001b[0m\t|\t\"'s\"            : 0.1  % \u001b[0m\t|\t'’s'            : 0.0  % \u001b[0m\n",
      "Token 35: ' a'            : 100.0% \u001b[0m\t|\t' collaborative' : 0.0  % \u001b[0m\t|\t' an'           : 0.0  % \u001b[0m\n",
      "Token 36: ' collaborative' : 100.0% \u001b[0m\t|\t' tool'         : 0.0  % \u001b[0m\t|\t' collaboration' : 0.0  % \u001b[0m\n",
      "Token 37: ' tool'         : 100.0% \u001b[0m\t|\t' tools'        : 0.0  % \u001b[0m\t|\t'tool'          : 0.0  % \u001b[0m\n",
      "Token 38: ' and'          : 60.93% \u001b[0m\t|\t','             : 10.59% \u001b[0m\t|\t' in'           : 10.59% \u001b[0m\n",
      "Token 39: ' and'          : 63.3 % \u001b[0m\t|\t' which'        : 23.29% \u001b[0m\t|\t' as'           : 9.71 % \u001b[0m\n",
      "Token 40: ' she'          : 61.39% \u001b[0m\t|\t' developed'    : 15.52% \u001b[0m\t|\t' developing'   : 5.71 % \u001b[0m\n",
      "Token 41: ' developed'    : 54.8 % \u001b[0m\t|\t' recognized'   : 17.79% \u001b[0m\t|\t' contributed'  : 6.55 % \u001b[0m\n",
      "Token 42: ' what'         : 68.9 % \u001b[0m\t|\t' the'          : 25.35% \u001b[0m\t|\t' an'           : 4.99 % \u001b[0m\n",
      "Token 43: ' first'        : 90.8 % \u001b[0m\t|\t' idea'         : 7.45 % \u001b[0m\t|\t' notion'       : 1.3  % \u001b[0m\n",
      "Token 44: ' computer'     : 79.58% \u001b[0m\t|\t' algorithm'    : 20.12% \u001b[0m\t|\t' known'        : 0.2  % \u001b[0m\n",
      "Token 45: ' program'      : 99.9 % \u001b[0m\t|\t' algorithm'    : 0.09 % \u001b[0m\t|\t' programming'  : 0.0  % \u001b[0m\n",
      "Token 46: ' through'      : 25.69% \u001b[0m\t|\t' in'           : 25.69% \u001b[0m\t|\t','             : 15.58% \u001b[0m\n",
      "Token 47: ' her'          : 99.94% \u001b[0m\t|\t' an'           : 0.04 % \u001b[0m\t|\t' the'          : 0.01 % \u001b[0m\n",
      "Token 48: ' notes'        : 94.97% \u001b[0m\t|\t' algorithm'    : 1.97 % \u001b[0m\t|\t' work'         : 1.35 % \u001b[0m\n",
      "Token 49: ' on'           : 99.84% \u001b[0m\t|\t' about'        : 0.05 % \u001b[0m\t|\t' related'      : 0.04 % \u001b[0m\n",
      "Token 50: ' the'          : 79.79% \u001b[0m\t|\t' B'            : 20.17% \u001b[0m\t|\t' Charles'      : 0.03 % \u001b[0m\n",
      "Token 51: ' Analytical'   : 100.0% \u001b[0m\t|\t' Anal'         : 0.0  % \u001b[0m\t|\t' analytical'   : 0.0  % \u001b[0m\n",
      "Token 52: ' Engine'       : 100.0% \u001b[0m\t|\t' engine'       : 0.0  % \u001b[0m\t|\t' Engineer'     : 0.0  % \u001b[0m\n",
      "Token 53: '.\",\"'          : 99.82% \u001b[0m\t|\t','             : 0.12 % \u001b[0m\t|\t'.'             : 0.03 % \u001b[0m\n",
      "Token 54: 'post'          : 100.0% \u001b[0m\t|\t'po'            : 0.0  % \u001b[0m\t|\t'pos'           : 0.0  % \u001b[0m\n",
      "Token 55: '_validation'   : 100.0% \u001b[0m\t|\t'_valid'        : 0.0  % \u001b[0m\t|\t'_val'          : 0.0  % \u001b[0m\n",
      "Token 56: '\":\"'           : 100.0% \u001b[0m\t|\t'\":\"\\''         : 0.0  % \u001b[0m\t|\t'\":\"+'          : 0.0  % \u001b[0m\n",
      "Token 57: \u001b[1m'Yes'           : 100.0% \u001b[0m\t|\t\u001b[1m'No'            : 0.0  % \u001b[0m\t|\t' Yes'          : 0.0  % \u001b[0m\n",
      "Token 58: '\"}'            : 100.0% \u001b[0m\t|\t'}'             : 0.0  % \u001b[0m\t|\t' \"}'           : 0.0  % \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "possible_tokens = test_all_completion.choices[0].logprobs.content\n",
    "print(\"Question: {}\".format(QUESTION))\n",
    "print(\n",
    "    \"Pre validation:\\t\\t{}\\nQuestion anser:\\t\\t{}\\nPost validation:\\t{}\".format(\n",
    "        test_all_message.parsed.pre_validation,\n",
    "        test_all_message.parsed.question_answer,\n",
    "        test_all_message.parsed.post_validation,\n",
    "    )\n",
    ")\n",
    "color_end_string = \"\\033[0m\"\n",
    "for i, token in enumerate(possible_tokens, start=1):\n",
    "    print(\"Token {:<2}: \".format(i), end=\"\")\n",
    "    for j, logprob in enumerate(token.top_logprobs):\n",
    "        if logprob.token == \"Yes\" or logprob.token == \"No\":\n",
    "            color_start_string = \"\\033[1m\"\n",
    "        else:\n",
    "            color_start_string = \"\"\n",
    "        print(\n",
    "            \"\"\"{}{:<15} : {:<5}% {}\"\"\".format(\n",
    "                color_start_string,\n",
    "                repr(logprob.token),\n",
    "                np.round(np.exp(logprob.logprob) * 100, 2),\n",
    "                color_end_string,\n",
    "            ),\n",
    "            end=\"\",\n",
    "        )\n",
    "        if j == len(token.top_logprobs) - 1:\n",
    "            print()\n",
    "        else:\n",
    "            print(\"\\t|\\t\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c258b83-2f14-446d-992a-f3f082f63fdd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b335e398-0377-49d1-bc11-548662370d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test_all(MODEL_NAME=\"gpt-4o-2024-08-06\"):\n",
    "\n",
    "    class ResponseFormat(BaseModel):\n",
    "        pre_validation: str = Field(\n",
    "            description=\"\"\"Before you answer, consider if you have sufficient information from the article to answer the question, respond with \"Yes\" or \"No\" only, nothing else.\"\"\"\n",
    "        )\n",
    "        question_answer: str = Field(\n",
    "            description=\"The answer of the question, nothing else. Anser Unknow if you do not have sufficient information from the article to answer the question.\"\n",
    "        )\n",
    "        post_validation: str = Field(\n",
    "            descrption=\"\"\"After providing your answer, evaluate whether your response is entirely based on the article's content and effectively answers the user's question., respond with \"Yes\" or \"No\" only, nothing else.\"\"\"\n",
    "        )\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_all_completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT.format(article=ARTICLE)},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=QUESTION)},\n",
    "        ],\n",
    "        response_format=ResponseFormat,\n",
    "        logprobs=True,\n",
    "        top_logprobs=TOP_LOGPROBS_NUM,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    cost_time = end_time - start_time\n",
    "    test_all_message = test_all_completion.choices[0].message\n",
    "    pre_validation_answer = test_all_message.parsed.pre_validation\n",
    "    question_answer = test_all_message.parsed.question_answer\n",
    "    post_validation_answer = test_all_message.parsed.post_validation\n",
    "    pre_validation_probability = np.round(\n",
    "        np.exp(test_all_completion.choices[0].logprobs.content[4].logprob) * 100, 2\n",
    "    )\n",
    "    post_validation_probability = np.round(\n",
    "        np.exp(test_all_completion.choices[0].logprobs.content[-2].logprob) * 100, 2\n",
    "    )\n",
    "    return (\n",
    "        pre_validation_answer,\n",
    "        pre_validation_probability,\n",
    "        question_answer,\n",
    "        post_validation_answer,\n",
    "        post_validation_probability,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        cost_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec32ee58-49f3-49d8-9b03-e4c436efb0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Yes',\n",
       " 99.75,\n",
       " 'Ada Lovelace built the concepts related to the Analytical Engine with Charles Babbage, including the idea that computers could have applications beyond mere calculation and could serve as collaborative tools for individuals and society.',\n",
       " 'Yes',\n",
       " 100.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 8.77829647064209)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_test_all(MODEL_NAME=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7dffc93-bdff-4641-9ccd-320ab4f5fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test_seperate(MODEL_NAME=\"gpt-4o-2024-08-06\"):\n",
    "    start_time = time.time()\n",
    "    test_1_completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_1.format(article=ARTICLE)},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=QUESTION)},\n",
    "        ],\n",
    "        logprobs=True,\n",
    "        top_logprobs=TOP_LOGPROBS_NUM,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    cost_time_1 = end_time - start_time\n",
    "    pre_validation_answer = test_1_completion.choices[0].message.content\n",
    "    pre_validation_probability = np.round(\n",
    "        np.exp(test_1_completion.choices[0].logprobs.content[0].logprob) * 100, 2\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_2_completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_2.format(article=ARTICLE)},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=QUESTION)},\n",
    "        ],\n",
    "        logprobs=True,\n",
    "        top_logprobs=TOP_LOGPROBS_NUM,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    cost_time_2 = end_time - start_time\n",
    "    question_answer = test_2_completion.choices[0].message.content\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_3_completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYS_PROMPT_3.format(article=ARTICLE, answer=question_answer),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=QUESTION)},\n",
    "        ],\n",
    "        logprobs=True,\n",
    "        top_logprobs=TOP_LOGPROBS_NUM,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    cost_time_3 = end_time - start_time\n",
    "    post_validation_answer = test_3_completion.choices[0].message.content\n",
    "    post_validation_probability = np.round(\n",
    "        np.exp(test_3_completion.choices[0].logprobs.content[0].logprob) * 100, 2\n",
    "    )\n",
    "    total_time = cost_time_3 + cost_time_2 + cost_time_1\n",
    "    return (\n",
    "        pre_validation_answer,\n",
    "        pre_validation_probability,\n",
    "        question_answer,\n",
    "        post_validation_answer,\n",
    "        post_validation_probability,\n",
    "        cost_time_1,\n",
    "        cost_time_2,\n",
    "        cost_time_3,\n",
    "        total_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1489cea7-6b4e-4579-87b6-2e3927086d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('No',\n",
       " 97.7,\n",
       " \"Lovelace built a long working relationship and friendship with Charles Babbage, focusing on his work on the Analytical Engine. She developed a vision of the capability of computers to go beyond mere calculating or number-crunching, as she examined how individuals and society relate to technology as a collaborative tool. Additionally, her notes on the Analytical Engine included what many consider to be the first computer program, demonstrating her understanding of the machine's applications.\",\n",
       " 'Yes',\n",
       " 99.68,\n",
       " 0.728041410446167,\n",
       " 1.6403543949127197,\n",
       " 0.35438108444213867,\n",
       " 2.7227768898010254)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_test_seperate(MODEL_NAME=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25b1763d-d0b0-4e35-8ebb-a6446732e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(5):\n",
    "    results.append([\"A\"] + list(llm_test_all()))\n",
    "    results.append([\"S\"] + list(llm_test_seperate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44ff28d4-ffe8-4138-a93a-8c13f710d29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Pre_prob</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Post</th>\n",
       "      <th>Post_prob</th>\n",
       "      <th>Time_pre</th>\n",
       "      <th>Time_answer</th>\n",
       "      <th>Time_post</th>\n",
       "      <th>Time_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>26.89</td>\n",
       "      <td>Do not have sufficent information to answer th...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>99.93</td>\n",
       "      <td>The article does not specify particular concep...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.48</td>\n",
       "      <td>1.102515</td>\n",
       "      <td>2.513767</td>\n",
       "      <td>0.353676</td>\n",
       "      <td>3.969959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>29.42</td>\n",
       "      <td>Do not have sufficent information to answer th...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>99.93</td>\n",
       "      <td>The article does not specify any particular co...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.98</td>\n",
       "      <td>0.373406</td>\n",
       "      <td>2.149766</td>\n",
       "      <td>0.373589</td>\n",
       "      <td>2.896761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Yes</td>\n",
       "      <td>77.73</td>\n",
       "      <td>Ada Lovelace and Charles Babbage worked togeth...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.802310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>99.99</td>\n",
       "      <td>The article does not specify particular concep...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.96</td>\n",
       "      <td>0.378137</td>\n",
       "      <td>1.701163</td>\n",
       "      <td>0.434065</td>\n",
       "      <td>2.513365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>Yes</td>\n",
       "      <td>77.73</td>\n",
       "      <td>Lovelace developed a vision of the capability ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.562442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>99.99</td>\n",
       "      <td>The article does not provide specific concepts...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.97</td>\n",
       "      <td>0.374094</td>\n",
       "      <td>1.431242</td>\n",
       "      <td>0.363143</td>\n",
       "      <td>2.168478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>Yes</td>\n",
       "      <td>79.82</td>\n",
       "      <td>Lovelace worked with Charles Babbage on the An...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.370857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "      <td>99.99</td>\n",
       "      <td>Lovelace was particularly interested in Charle...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>99.99</td>\n",
       "      <td>0.380145</td>\n",
       "      <td>2.582684</td>\n",
       "      <td>0.390399</td>\n",
       "      <td>3.353228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Pre  Pre_prob                                             Answer Post  \\\n",
       "0    A   No     26.89  Do not have sufficent information to answer th...  Yes   \n",
       "1    S   No     99.93  The article does not specify particular concep...  Yes   \n",
       "2    A   No     29.42  Do not have sufficent information to answer th...  Yes   \n",
       "3    S   No     99.93  The article does not specify any particular co...  Yes   \n",
       "4    A  Yes     77.73  Ada Lovelace and Charles Babbage worked togeth...  Yes   \n",
       "5    S   No     99.99  The article does not specify particular concep...  Yes   \n",
       "6    A  Yes     77.73  Lovelace developed a vision of the capability ...  Yes   \n",
       "7    S   No     99.99  The article does not provide specific concepts...  Yes   \n",
       "8    A  Yes     79.82  Lovelace worked with Charles Babbage on the An...  Yes   \n",
       "9    S   No     99.99  Lovelace was particularly interested in Charle...  Yes   \n",
       "\n",
       "   Post_prob  Time_pre  Time_answer  Time_post  Time_total  \n",
       "0      99.99       NaN          NaN        NaN    1.609255  \n",
       "1      99.48  1.102515     2.513767   0.353676    3.969959  \n",
       "2     100.00       NaN          NaN        NaN    1.000639  \n",
       "3      99.98  0.373406     2.149766   0.373589    2.896761  \n",
       "4     100.00       NaN          NaN        NaN    1.802310  \n",
       "5      99.96  0.378137     1.701163   0.434065    2.513365  \n",
       "6     100.00       NaN          NaN        NaN    1.562442  \n",
       "7      99.97  0.374094     1.431242   0.363143    2.168478  \n",
       "8     100.00       NaN          NaN        NaN    1.370857  \n",
       "9      99.99  0.380145     2.582684   0.390399    3.353228  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"Type\",\n",
    "        \"Pre\",\n",
    "        \"Pre_prob\",\n",
    "        \"Answer\",\n",
    "        \"Post\",\n",
    "        \"Post_prob\",\n",
    "        \"Time_pre\",\n",
    "        \"Time_answer\",\n",
    "        \"Time_post\",\n",
    "        \"Time_total\"\n",
    "    ],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11e1c242-be0b-45b3-95b0-3c06e6beff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4691008567810058"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Type\"] == \"A\"][\"Time_total\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9cf62248-96cc-4c53-a582-7c70d3aa5950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9803582668304442"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Type\"] == \"S\"][\"Time_total\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289243ca-fc93-4682-a566-ef6860d7bc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915f2bc-3045-42d7-952b-5185c13504b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
